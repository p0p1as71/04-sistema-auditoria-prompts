# ğŸ›¡ï¸ Framework de AuditorÃ­a TÃ©cnica de Prompts (v1.5.2)

Sistema de nivel empresarial para la validaciÃ³n de agentes en el ecosistema A.M.O. Este repositorio contiene la infraestructura de testing para asegurar que cada mÃ³dulo cumpla con los estÃ¡ndares de calidad antes del despliegue.

## ğŸ¤– M12 - Motor de Scoring y MÃ©tricas (El Evaluador)

El M12 es el corazÃ³n de la calidad del sistema. ActÃºa bajo una arquitectura de **"IA auditando IA"** para eliminar la subjetividad en la validaciÃ³n de prompts.

### ğŸ”— Interconectividad de MÃ³dulos
* **M12 â¡ï¸ M14:** Si el **scoring es < 7/9**, se emite un `error_flag: true` que activa automÃ¡ticamente el protocolo de re-intento (Tenacity) en el motor de orquestaciÃ³n.
* **M12 â¡ï¸ M13:** EnvÃ­a mÃ©tricas de **precisiÃ³n (â­)** y robustez para el Dashboard de supervisiÃ³n y control de seguridad.

### ğŸ“ˆ MetodologÃ­a de EvaluaciÃ³n
1. **Scoring Estructural:** Escala 1-9 (AprobaciÃ³n en 7/9).
2. **MÃ©tricas Cualitativas:** Escala de estrellas (â­) para el campo de precisiÃ³n.
3. **IdentificaciÃ³n de Modelo:** Registro obligatorio del `modelo_ejecutor` (ej. GPT-4o-mini).

### ğŸ› ï¸ Evidencia TÃ©cnica
El sistema es validado automÃ¡ticamente mediante **Promptfoo**, asegurando que la salida JSON sea siempre compatible con la base de datos de Notion.

```bash
# Comando de validaciÃ³n
npx promptfoo eval